{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier,\\\n",
    "                                ExtraTreesClassifier, AdaBoostClassifier,\\\n",
    "                                GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset of selftext & title\n",
    "df = pd.read_csv('./Datasets/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with [removed]\n",
    "df.fillna('[removed]', inplace = True)\n",
    "\n",
    "# Merge title and selftext\n",
    "df['title_selftext'] = df[['title', 'selftext']].apply(lambda x: ''.join(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vadersentiment to determine the negative, neutral, positive, and compound for the title and selftext\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "storage_sf = []\n",
    "for text in df['title_selftext']:\n",
    "    score = sia.polarity_scores(text)\n",
    "    score['title_selftext'] = text\n",
    "    storage_sf.append(score)\n",
    "df_final = pd.DataFrame(storage_sf)\n",
    "df_final['subreddit'] = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by subreddits\n",
    "df_final.groupby('subreddit').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the X & y and seperatate through train_test_split\n",
    "X = df_final[['compound', 'title_selftext']]\n",
    "y = df_final['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TfidfVectorize to fit and train the title and self text. Also using the stop_words = 'english'\n",
    "# This was the best result from the EDA and Modeling\n",
    "tf = TfidfVectorizer(stop_words = 'english')\n",
    "X_train_tf = tf.fit_transform(X_train['title_selftext']).todense()\n",
    "X_test_tf = tf.transform(X_test['title_selftext']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 2.5, 5, 7.5, 10], 'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Logistic Regression to create a model under both penalties and multiple C values\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "params = ({\n",
    "    'C': [1, 2.5, 5, 7.5, 10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "})\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid = params, cv = 5)\n",
    "gs.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466003950806092"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Score\n",
    "gs.score(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792048929663608"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Score\n",
    "gs.score(X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.5, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the probability that the results will be 1\n",
    "y_score_proba = [i[1] for i in gs.predict_proba(X_test_tf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05771217992127215,\n",
       " 0.9336195785459218,\n",
       " 0.878626183530915,\n",
       " 0.9722331671338049,\n",
       " 0.9875401399480769,\n",
       " 0.010548676024082432,\n",
       " 0.05172570703757097,\n",
       " 0.41590999705687276,\n",
       " 0.9732931376203348,\n",
       " 0.0006427716273510172,\n",
       " 0.9965331144110487,\n",
       " 0.9748645562151972,\n",
       " 0.9967602990507223,\n",
       " 0.9143311789619304,\n",
       " 0.9761847917112629,\n",
       " 0.31707998004802024,\n",
       " 0.0987614838734503,\n",
       " 0.7223112620223895,\n",
       " 0.02956729127148435,\n",
       " 0.38096627140681916,\n",
       " 0.9439665536239364,\n",
       " 0.7153636430939979,\n",
       " 0.8460958489568108,\n",
       " 0.8188856125291847,\n",
       " 0.3602897160768578,\n",
       " 0.8747830206743711,\n",
       " 0.006210162145941955,\n",
       " 0.5203090229229452,\n",
       " 0.9382292468909836,\n",
       " 0.06964354831397038,\n",
       " 0.55666088892899,\n",
       " 0.03275148703605472,\n",
       " 0.5443177065951319,\n",
       " 0.9249461463800188,\n",
       " 0.031482878786882613,\n",
       " 0.8756452593194161,\n",
       " 0.43240198867295765,\n",
       " 0.8758784376702919,\n",
       " 0.7943440046568223,\n",
       " 0.907182508749629,\n",
       " 0.9422679981031746,\n",
       " 0.9848080167223419,\n",
       " 0.7193464321485823,\n",
       " 0.3025912823618392,\n",
       " 0.9770242243867036,\n",
       " 0.8826726658989145,\n",
       " 0.5859279073637252,\n",
       " 0.3428353849073283,\n",
       " 0.7946600469703484,\n",
       " 0.1623089689739071,\n",
       " 0.8207475607727893,\n",
       " 0.002360062280245203,\n",
       " 0.9797486343758253,\n",
       " 0.07725577016534066,\n",
       " 0.14547346012128806,\n",
       " 0.2370609814779873,\n",
       " 0.7857299679924178,\n",
       " 0.05588927952570232,\n",
       " 0.5013049513344987,\n",
       " 0.4216919459318155,\n",
       " 0.2099003061904559,\n",
       " 0.17746123289032606,\n",
       " 0.9828356585747601,\n",
       " 0.12384026820524263,\n",
       " 0.519158332869921,\n",
       " 0.06541847089958872,\n",
       " 0.46835576174002375,\n",
       " 0.003476890472593992,\n",
       " 0.7615644254464125,\n",
       " 0.42217471758603353,\n",
       " 0.8536214248469758,\n",
       " 0.9218746093965525,\n",
       " 0.9645069072976227,\n",
       " 0.0029099684229965013,\n",
       " 0.9204897865781562,\n",
       " 0.928650139903823,\n",
       " 0.9761186334317398,\n",
       " 0.008564995827254451,\n",
       " 0.9770871533667237,\n",
       " 0.8995791575891939,\n",
       " 0.026444263753468547,\n",
       " 0.9991446974638232,\n",
       " 0.9566235193877798,\n",
       " 0.00025217872017500506,\n",
       " 0.9979021202378182,\n",
       " 0.004422659923601953,\n",
       " 0.9094554861996841,\n",
       " 0.0119013096086399,\n",
       " 0.0010032753429895386,\n",
       " 0.9135601598506901,\n",
       " 0.08011260556083977,\n",
       " 0.3085279763390592,\n",
       " 0.8681037950778087,\n",
       " 0.10480056743239914,\n",
       " 0.7464657372902939,\n",
       " 0.30404313173217223,\n",
       " 0.9318955629858232,\n",
       " 0.9597263181866943,\n",
       " 0.7215519827799862,\n",
       " 0.005370172100849207,\n",
       " 0.8994468309344094,\n",
       " 0.8432950187100395,\n",
       " 0.3124944001883898,\n",
       " 0.08658699701837803,\n",
       " 0.9511981656904943,\n",
       " 0.6070762890680022,\n",
       " 0.5408218248399977,\n",
       " 0.01250160020095407,\n",
       " 0.060449356966941384,\n",
       " 0.11158036116087022,\n",
       " 0.3330201921159198,\n",
       " 0.8316242539508167,\n",
       " 0.8177139023879864,\n",
       " 0.8141625769159575,\n",
       " 0.5053579248210172,\n",
       " 0.2210824680373878,\n",
       " 0.017753907873823555,\n",
       " 0.985991662046371,\n",
       " 0.23402438917781732,\n",
       " 0.7889769939810775,\n",
       " 0.0001979544726130723,\n",
       " 0.943912325895886,\n",
       " 0.002373779168382672,\n",
       " 0.986766726752596,\n",
       " 0.979868059541501,\n",
       " 0.8714193938865126,\n",
       " 0.7334506724888823,\n",
       " 0.7116580151952375,\n",
       " 0.46590051247460873,\n",
       " 0.2381200157597654,\n",
       " 0.7381329113468514,\n",
       " 0.2644302805902118,\n",
       " 0.0025809303396877566,\n",
       " 0.23079189131911282,\n",
       " 0.2254756710119115,\n",
       " 0.006543355234101963,\n",
       " 0.8777719583655061,\n",
       " 0.018632757367654663,\n",
       " 0.49053882055488673,\n",
       " 0.8920052403107614,\n",
       " 0.6100984319416921,\n",
       " 0.8626304919867658,\n",
       " 0.27830932926900953,\n",
       " 0.609071178814066,\n",
       " 0.40752368376116266,\n",
       " 0.6193838612272977,\n",
       " 0.5936882461601006,\n",
       " 0.0002235221732232277,\n",
       " 0.5940102231538898,\n",
       " 0.3042902933303216,\n",
       " 0.963586819229244,\n",
       " 0.5194931523934445,\n",
       " 0.0005027572489022424,\n",
       " 0.41396306482458306,\n",
       " 0.0005325190634860791,\n",
       " 0.3023278261467868,\n",
       " 0.219038797844739,\n",
       " 0.0654368043111022,\n",
       " 0.17792456794854866,\n",
       " 0.8132268717028402,\n",
       " 0.8488609240699956,\n",
       " 0.6656613350633602,\n",
       " 0.22184115563064907,\n",
       " 0.6407278988459912,\n",
       " 0.06893206747869288,\n",
       " 0.6888760646400145,\n",
       " 0.003942198407861399,\n",
       " 0.0006763740534594512,\n",
       " 0.20059692978192115,\n",
       " 0.034878418335203616,\n",
       " 0.9688602347971077,\n",
       " 0.5625283400686992,\n",
       " 0.9076434025020641,\n",
       " 0.13170576341680917,\n",
       " 0.03589735300331573,\n",
       " 0.4380884806997165,\n",
       " 0.1802010024077186,\n",
       " 0.9453357569204871,\n",
       " 0.2571069716630658,\n",
       " 0.5521896624457613,\n",
       " 0.05993199988056799,\n",
       " 0.08266345805793401,\n",
       " 0.01373607018050017,\n",
       " 0.9691079161524132,\n",
       " 0.16108699933998005,\n",
       " 0.9472613762406389,\n",
       " 0.982356447457035,\n",
       " 3.0584925016226164e-05,\n",
       " 0.8285959488044785,\n",
       " 0.008952759461082137,\n",
       " 0.9174495425912373,\n",
       " 0.21610149485059907,\n",
       " 0.21106603977975577,\n",
       " 0.922087191687417,\n",
       " 0.7504996832440431,\n",
       " 0.038801884155677646,\n",
       " 0.00271817228891136,\n",
       " 0.6925257191830958,\n",
       " 0.8939489750218309,\n",
       " 0.05107588740296872,\n",
       " 0.9335490109598028,\n",
       " 0.5490716977983122,\n",
       " 0.7016653476069067,\n",
       " 0.9679260799699019,\n",
       " 0.020437684591215016,\n",
       " 0.9761920856974066,\n",
       " 0.24151353817628804,\n",
       " 0.9688993502800585,\n",
       " 0.1320067812810532,\n",
       " 0.9896803272802935,\n",
       " 0.8260495935344632,\n",
       " 0.9866555108178132,\n",
       " 0.09842728267658106,\n",
       " 0.8161789112849065,\n",
       " 0.24009415060014958,\n",
       " 0.10321553536784298,\n",
       " 0.9864962008595198,\n",
       " 0.3949248310025554,\n",
       " 3.0584925016226164e-05,\n",
       " 0.8242833985849205,\n",
       " 0.9881125848889025,\n",
       " 0.8419771282647772,\n",
       " 0.9649345783534885,\n",
       " 0.9814989629562159,\n",
       " 0.8136604179387057,\n",
       " 0.055499955669254634,\n",
       " 0.18460703629772302,\n",
       " 0.9459527318857609,\n",
       " 0.05930315716257032,\n",
       " 0.9119980774132805,\n",
       " 0.8536008290009411,\n",
       " 3.0584925016226164e-05,\n",
       " 0.01680008386436208,\n",
       " 0.053964274670154085,\n",
       " 0.7736854247573292,\n",
       " 0.9487844839418265,\n",
       " 0.7934547108433607,\n",
       " 0.05602894553097627,\n",
       " 0.011060880359098111,\n",
       " 0.2291375834149639,\n",
       " 0.698371117677713,\n",
       " 0.5536610394286766,\n",
       " 0.6461887204435469,\n",
       " 0.20200862793179056,\n",
       " 0.9940229420160264,\n",
       " 0.8055561531895712,\n",
       " 0.3949651101879873,\n",
       " 0.9889488546060077,\n",
       " 0.977664440113271,\n",
       " 0.7527023095048554,\n",
       " 0.912828531887864,\n",
       " 0.02727607344159193,\n",
       " 0.027149182071274668,\n",
       " 0.29067436667544666,\n",
       " 0.4915822658711974,\n",
       " 0.20834849243970893,\n",
       " 0.07229299800781813,\n",
       " 0.6048464626783525,\n",
       " 0.01840100904521744,\n",
       " 0.9750360296913639,\n",
       " 0.8838785007659231,\n",
       " 0.24393590821849642,\n",
       " 0.6691488808200966,\n",
       " 0.0002599363570974258,\n",
       " 0.8851201787888595,\n",
       " 0.3994809470812842,\n",
       " 0.10628644400482697,\n",
       " 0.8053720465289633,\n",
       " 0.990573329754664,\n",
       " 0.3031808902264643,\n",
       " 0.27420361810037264,\n",
       " 0.11316838464564105,\n",
       " 0.6441572178857483,\n",
       " 0.00998637317994516,\n",
       " 0.8841041449406285,\n",
       " 0.9253368951996277,\n",
       " 0.9290094432628948,\n",
       " 0.8998722405181203,\n",
       " 0.06771225994397866,\n",
       " 0.054735431833004874,\n",
       " 0.3207567195810897,\n",
       " 0.003044126790546509,\n",
       " 0.8517827384375256,\n",
       " 0.4520295913786089,\n",
       " 0.885218536349217,\n",
       " 0.019439645027363978,\n",
       " 0.8222714642167251,\n",
       " 0.9553428693197025,\n",
       " 0.41586736243825495,\n",
       " 0.9448809212958879,\n",
       " 0.1774878697437767,\n",
       " 0.02969180915710666,\n",
       " 0.6537222273963742,\n",
       " 0.8122395127060001,\n",
       " 0.29603810311323997,\n",
       " 0.9972863822420015,\n",
       " 0.9189906658398632,\n",
       " 0.9027438084730125,\n",
       " 0.9871846869178366,\n",
       " 0.9378609222469013,\n",
       " 0.34970048387499214,\n",
       " 0.05473905632472598,\n",
       " 0.7194582612670792,\n",
       " 0.9921186275248657,\n",
       " 0.5504182016113999,\n",
       " 0.31655230250936894,\n",
       " 0.8412404841427572,\n",
       " 0.06518144928571988,\n",
       " 0.9335175873184057,\n",
       " 0.5255735284728684,\n",
       " 0.30102900389137877,\n",
       " 0.04287017114304362,\n",
       " 0.6938865909813486,\n",
       " 0.07333188749653076,\n",
       " 0.4843092590824885,\n",
       " 0.264675278498035,\n",
       " 0.7771275451532463,\n",
       " 0.9911288191366704,\n",
       " 0.29061587401275396,\n",
       " 0.9675407725722364,\n",
       " 0.9511134096288667,\n",
       " 0.7000294969947756,\n",
       " 0.45730538265505966,\n",
       " 0.8395938166102639,\n",
       " 0.2567652738480236,\n",
       " 0.9823031009967824,\n",
       " 0.9991981224057218,\n",
       " 0.018120624870538126,\n",
       " 0.06329576041005308,\n",
       " 0.0005456784401059566,\n",
       " 0.11007096471227867,\n",
       " 0.11356029588900288,\n",
       " 0.9967602990507223,\n",
       " 0.3119082319699241,\n",
       " 0.9951437239633648,\n",
       " 0.8594618190005848,\n",
       " 0.9977192637011375,\n",
       " 0.021354165551906595,\n",
       " 0.9771738972775893,\n",
       " 0.08957607724535993,\n",
       " 0.8791438493307308,\n",
       " 0.8349006454166775,\n",
       " 0.004145914777700618,\n",
       " 0.017136104353009402,\n",
       " 0.8663214055319696,\n",
       " 0.029285722764924974,\n",
       " 0.11460704939043338,\n",
       " 0.07966823612449113,\n",
       " 0.4278703144386859,\n",
       " 0.6633609110159681,\n",
       " 0.09444707599575868,\n",
       " 0.4326798390452114,\n",
       " 0.0002235221732232277,\n",
       " 0.14549275299547862,\n",
       " 0.9967602990507223,\n",
       " 0.07050434924260428,\n",
       " 0.9429708555587762,\n",
       " 0.9662136889941537,\n",
       " 0.1802883398905843,\n",
       " 0.9616049680118809,\n",
       " 0.2803297608007708,\n",
       " 0.019983209198768823,\n",
       " 0.9643574573771935,\n",
       " 3.0584925016226164e-05,\n",
       " 0.16999573549699856,\n",
       " 0.9519471205290276,\n",
       " 0.035842192925106,\n",
       " 0.005806770193693154,\n",
       " 0.36668122359565,\n",
       " 0.933675467065899,\n",
       " 0.8419747672504088,\n",
       " 0.5330870346368819,\n",
       " 0.08496729198426989,\n",
       " 0.9575522537919963,\n",
       " 0.6152843332113413,\n",
       " 0.03286329467427795,\n",
       " 0.3751725459357044,\n",
       " 0.9323306171019385,\n",
       " 0.5837309086516141,\n",
       " 0.1728290549275487,\n",
       " 0.8954681106216685,\n",
       " 0.05876528300518203,\n",
       " 0.01626841684042731,\n",
       " 0.23280816884908137,\n",
       " 0.8548859292456122,\n",
       " 0.06204274022367734,\n",
       " 0.17638000291078573,\n",
       " 0.175949843065339,\n",
       " 0.01338506039374243,\n",
       " 0.8691313675259885,\n",
       " 0.9073691559730211,\n",
       " 0.03763544721908296,\n",
       " 0.020273309436912395,\n",
       " 0.9978445281110476,\n",
       " 0.9906591606098623,\n",
       " 0.9292424817774056,\n",
       " 0.7400846286798786,\n",
       " 0.14576393321383255,\n",
       " 0.8344474690551164,\n",
       " 0.9153118600523759,\n",
       " 0.1298378138595981,\n",
       " 0.5620116848911912,\n",
       " 0.050907022094092085,\n",
       " 0.15662957413668496,\n",
       " 0.19595323930834524,\n",
       " 0.19630594696604026,\n",
       " 0.7824593531370094,\n",
       " 0.7906143661879603,\n",
       " 0.0020088847219586195,\n",
       " 0.05282420333025002,\n",
       " 0.9718963487303866,\n",
       " 0.9929363427860073,\n",
       " 0.2453614059242219,\n",
       " 0.4882370211768941,\n",
       " 0.39425549873170623,\n",
       " 0.0015858001197849182,\n",
       " 0.8238159442410763,\n",
       " 0.6466786283742724,\n",
       " 0.04397124446827169,\n",
       " 0.7500465107917962,\n",
       " 0.9252214883194311,\n",
       " 0.010840336344638744,\n",
       " 0.9477288780248365,\n",
       " 0.045936833273340506,\n",
       " 0.8349548848106533,\n",
       " 0.715860201616422,\n",
       " 0.9261028228388641,\n",
       " 0.8823646365637342,\n",
       " 0.851624350649244,\n",
       " 0.006502253969341667,\n",
       " 0.030767069242380332,\n",
       " 0.08691964741541401,\n",
       " 0.2389635558607107,\n",
       " 0.011113657445160234,\n",
       " 0.035508194593695114,\n",
       " 0.26535934569240965,\n",
       " 0.04349193227199159,\n",
       " 0.9972611813989566,\n",
       " 0.09977084388993973,\n",
       " 0.4349391720640685,\n",
       " 0.007832963284765678,\n",
       " 0.003958325724014719,\n",
       " 0.9099815169173212,\n",
       " 0.8833377480989246,\n",
       " 0.0002589552578184561,\n",
       " 0.22542329784562895,\n",
       " 0.048703798936160315,\n",
       " 0.22306008900789756,\n",
       " 0.9242288233793664,\n",
       " 0.9843495526942887,\n",
       " 0.9670671366740408,\n",
       " 0.9643191073035674,\n",
       " 0.6478254208325758,\n",
       " 0.7683765305438263,\n",
       " 0.13657755842505925,\n",
       " 0.32166994296135726,\n",
       " 0.8944068278973416,\n",
       " 0.007492503349340732,\n",
       " 0.036059913459362845,\n",
       " 0.9502915727785638,\n",
       " 0.8708981498172074,\n",
       " 0.9197942150906311,\n",
       " 0.00135623292789252,\n",
       " 0.01141491414312467,\n",
       " 0.14524478279218672,\n",
       " 0.02365061883820471,\n",
       " 0.03735024638544766,\n",
       " 0.17806127595532245,\n",
       " 0.9218443192102663,\n",
       " 0.984536830623613,\n",
       " 0.7341201039375244,\n",
       " 0.054764629944182165,\n",
       " 0.3974716513685617,\n",
       " 0.0657664563133509,\n",
       " 0.31332716695586604,\n",
       " 0.9903985810232274,\n",
       " 0.19735117674986785,\n",
       " 0.9449594294358065,\n",
       " 0.008886355325867335,\n",
       " 0.9723150574336483,\n",
       " 0.313467450029134,\n",
       " 0.1131938410020183,\n",
       " 0.5470197859742776,\n",
       " 0.8904874603612185,\n",
       " 0.7031736759309546,\n",
       " 0.9662838731796367,\n",
       " 0.03528385676072832,\n",
       " 0.955582655308521,\n",
       " 0.10792667052555256,\n",
       " 0.9691922395802235,\n",
       " 0.11970798722766385,\n",
       " 0.14632462164719182,\n",
       " 0.4596496668350954,\n",
       " 0.25946721620268115,\n",
       " 0.6399826639057601,\n",
       " 0.6643641852547252,\n",
       " 0.21020206606705694,\n",
       " 0.7906224554333293,\n",
       " 0.14301726627801267,\n",
       " 0.990786623146609,\n",
       " 0.3921651113780439,\n",
       " 0.043757660093317885,\n",
       " 0.7752364272773449,\n",
       " 0.09426544428558778,\n",
       " 0.08440869074032781,\n",
       " 0.9999923030980978,\n",
       " 0.20830481283968197,\n",
       " 0.9009656667174463,\n",
       " 0.3877371119094306,\n",
       " 0.06214450133154637,\n",
       " 0.9626188614412922,\n",
       " 0.01858504821974812,\n",
       " 0.8962631064968135,\n",
       " 0.9915928493509842,\n",
       " 0.13271678222662123,\n",
       " 0.9724424578620408,\n",
       " 0.9041539349108333,\n",
       " 0.45685573851298267,\n",
       " 0.43268827286108885,\n",
       " 0.048356759380424164,\n",
       " 0.9872771217281737,\n",
       " 0.5016553531666788,\n",
       " 0.002832430337723028,\n",
       " 0.044856336845394335,\n",
       " 0.6274001579076344,\n",
       " 0.26548107753406813,\n",
       " 0.010433731904776351,\n",
       " 0.0021940698454442588,\n",
       " 0.008236619354363652,\n",
       " 0.07597392616344194,\n",
       " 0.12142256370428464,\n",
       " 0.1838905547962306,\n",
       " 0.0297182350435156,\n",
       " 0.9673625305668538,\n",
       " 0.8930558655497958,\n",
       " 0.999405667859565,\n",
       " 0.7003819208666963,\n",
       " 0.21126094733545583,\n",
       " 0.9815358868152982,\n",
       " 0.8640821323457107,\n",
       " 0.583685931457541,\n",
       " 0.9604729003837185,\n",
       " 0.31352957633892653,\n",
       " 0.14426416991259694,\n",
       " 0.9914595304953083,\n",
       " 0.8847155590855897,\n",
       " 0.29089341412001757,\n",
       " 0.9808446416709605,\n",
       " 0.9174270196137837,\n",
       " 0.07153641580481743,\n",
       " 0.1780636256119031,\n",
       " 0.983500823955511,\n",
       " 0.5765946694163858,\n",
       " 0.986581513622928,\n",
       " 0.025876449315830278,\n",
       " 0.11932300770418669,\n",
       " 0.3007446454737508,\n",
       " 0.2015629842518293,\n",
       " 0.08808189939705713,\n",
       " 0.9872751446181754,\n",
       " 0.9941167570796549,\n",
       " 3.0584925016226164e-05,\n",
       " 0.3756110081019079,\n",
       " 0.8554082300296678,\n",
       " 0.0006157145665963347,\n",
       " 0.5168678994314007,\n",
       " 0.8840158932638942,\n",
       " 0.9475625780028719,\n",
       " 0.8655499324560104,\n",
       " 0.4541418726493868,\n",
       " 0.7751629581528452,\n",
       " 0.9552609243893694,\n",
       " 0.9169020616113464,\n",
       " 0.9190769585222178,\n",
       " 0.07054839559065516,\n",
       " 0.5811590163791871,\n",
       " 0.9063457942467489,\n",
       " 0.5047388935957059,\n",
       " 0.09014876892082466,\n",
       " 0.17903438582031822,\n",
       " 0.9847432062809528,\n",
       " 0.9847319738879214,\n",
       " 0.011178276397163792,\n",
       " 0.8337905665182291,\n",
       " 0.35767552299057864,\n",
       " 0.1572886513635586,\n",
       " 0.04846494727962752,\n",
       " 0.9530087970037248,\n",
       " 0.9480428780628043,\n",
       " 0.4590317311603902,\n",
       " 0.9012055430625815,\n",
       " 0.10530201082277015,\n",
       " 0.010455321563401471,\n",
       " 0.3581033345286357,\n",
       " 0.5883152715948864,\n",
       " 0.49307653770001975,\n",
       " 0.9962221910119485,\n",
       " 0.780189247126871,\n",
       " 0.8414666420356761,\n",
       " 0.8996171604581535,\n",
       " 0.9975654380328219,\n",
       " 0.7059531204680551,\n",
       " 0.9085140928412768,\n",
       " 0.9669867243990492,\n",
       " 0.01332108537062151,\n",
       " 0.30826387633869395,\n",
       " 0.9859358897651653,\n",
       " 0.04523390165106965,\n",
       " 0.7776740953926925,\n",
       " 0.0467040111265249,\n",
       " 0.8952677232579278,\n",
       " 0.07640576812760982,\n",
       " 0.9001713248873938,\n",
       " 0.7867180122172033,\n",
       " 0.013931072277615423,\n",
       " 0.0706483559773607,\n",
       " 0.5414707173775573,\n",
       " 0.029123342302333197,\n",
       " 0.5319805083761557,\n",
       " 0.0074687804951678325,\n",
       " 0.9901692971057567,\n",
       " 0.880207839917878,\n",
       " 0.94184494691058,\n",
       " 0.9354640696685876,\n",
       " 0.6408782099721148,\n",
       " 0.02395279967975915,\n",
       " 0.8893929579101407,\n",
       " 0.965640469957578,\n",
       " 0.02515755657008335,\n",
       " 0.05219694165032188,\n",
       " 0.9184665556034433,\n",
       " 0.42155270870553563,\n",
       " 0.9708882411662272,\n",
       " 0.01573131319634187,\n",
       " 0.8079042340280231,\n",
       " 0.10845990813677825,\n",
       " 0.9892583642429398,\n",
       " 0.571262408269175,\n",
       " 0.9874661916319104,\n",
       " 0.20828235724265015,\n",
       " 0.8989349244553541,\n",
       " 0.6317603856499131,\n",
       " 0.7845620881148089,\n",
       " 0.6179240873342449,\n",
       " 0.8822618317289018,\n",
       " 0.0016257509735450547,\n",
       " 0.002432995875792371,\n",
       " 0.8419001226896172,\n",
       " 0.895352160027144,\n",
       " 0.09804560324383545,\n",
       " 0.9848356494131696,\n",
       " 0.6020460822495793,\n",
       " 0.0837365540771147,\n",
       " 0.956803159120657,\n",
       " 0.9045891382443413,\n",
       " 0.9843887389188187,\n",
       " 0.061365531281176534,\n",
       " 0.9929563387178498,\n",
       " 0.9653953902086413,\n",
       " 0.3193690484241885,\n",
       " 0.18583745994029843,\n",
       " 0.28391587686682007,\n",
       " 0.47661346975951363,\n",
       " 0.11901452761243364,\n",
       " 0.015893712795461035,\n",
       " 0.9830597511474023,\n",
       " 0.9531762997898378,\n",
       " 0.28000785790578875,\n",
       " 0.9663386084025412,\n",
       " 0.29374849443640927,\n",
       " 0.796705722175927,\n",
       " 0.020280604052891487,\n",
       " 0.05713191660041466,\n",
       " 0.6768878163911736,\n",
       " 0.0026317455528082957,\n",
       " 0.7358472548271746,\n",
       " 0.02373830342055396,\n",
       " 0.2673730581043755,\n",
       " 0.0009018746619221862,\n",
       " 0.7828754012788534,\n",
       " 0.7040728668278678,\n",
       " 0.9140016865154937,\n",
       " 0.9490916823218323,\n",
       " 0.749658520578166,\n",
       " 0.9495321002514405,\n",
       " 0.46702708245004376,\n",
       " 0.027335162020102815,\n",
       " 0.2647377206222365,\n",
       " 0.6645488472506087,\n",
       " 0.9650233124131098,\n",
       " 0.9605379592657459,\n",
       " 0.0723460400322172,\n",
       " 0.10700773359330368,\n",
       " 0.6936855401788778,\n",
       " 0.18601025973247984,\n",
       " 0.019381035272108597,\n",
       " 0.8015913491759978,\n",
       " 0.009195986634105108,\n",
       " 0.6288206734833619,\n",
       " 0.47851866391335557,\n",
       " 0.1533046165748301,\n",
       " 0.015400442285416429,\n",
       " 0.0007397766920693466,\n",
       " 0.9349447763560605,\n",
       " 0.0007558370354029058,\n",
       " 0.9820365360106444,\n",
       " 0.7281389830909586,\n",
       " 0.9986637657181703,\n",
       " 0.4443943314277014,\n",
       " 0.06938175396866883,\n",
       " 0.1892718943644789,\n",
       " 0.8298411242911529,\n",
       " 0.1662057535546691,\n",
       " 0.10506036851889893,\n",
       " 0.6230436704561696,\n",
       " 0.003069417757161146,\n",
       " 0.11127399929763525,\n",
       " 0.9936991005968921,\n",
       " 0.3231467077295465,\n",
       " 0.9307224735647255,\n",
       " 0.541232632703309,\n",
       " 0.008138979760399229,\n",
       " 0.043805574542721604,\n",
       " 0.4854729139798582,\n",
       " 0.010435758430451397,\n",
       " 0.9335870026446269,\n",
       " 0.7801996976112351,\n",
       " 0.9943398566210959,\n",
       " 0.16450044962806917,\n",
       " 0.32525154755830404,\n",
       " 0.8170449429425395,\n",
       " 0.988997001857418,\n",
       " 0.10696638884644032,\n",
       " 0.3646855013839256,\n",
       " 0.04194695729487108,\n",
       " 0.15823866923317317,\n",
       " 0.847991839123453,\n",
       " 0.9561861874673281,\n",
       " 0.5039809179387,\n",
       " 0.4132993215052133,\n",
       " 0.0045282130968089035,\n",
       " 0.005459614307199459,\n",
       " 0.026532404591769896,\n",
       " 0.9392712066763333,\n",
       " 0.9748324279918927,\n",
       " 0.8826906028208232,\n",
       " 0.36719160764140263,\n",
       " 0.986752458158997,\n",
       " 0.9981985299542009,\n",
       " 0.017621019333154565,\n",
       " 0.10992824067536458,\n",
       " 0.9620453327894208,\n",
       " 0.9442503706873393,\n",
       " 0.9984621180927749,\n",
       " 0.8337604300826166,\n",
       " 0.026042877259141665,\n",
       " 0.49247259473912075,\n",
       " 0.2553129092574812,\n",
       " 0.05098773871876595,\n",
       " 0.02374964135643721,\n",
       " 0.9888757548615242,\n",
       " 0.08942239823163357,\n",
       " 0.9792209093641849,\n",
       " 0.0055903557273322595,\n",
       " 0.003813324350350873,\n",
       " 0.4420021833109424,\n",
       " 0.0905798260598624,\n",
       " 0.7011172837388189,\n",
       " 0.06656878452435598,\n",
       " 0.1987018901685194,\n",
       " 0.7369888105656517,\n",
       " 0.9755484773998271,\n",
       " 0.9862265573902351,\n",
       " 0.7005851423450967,\n",
       " 0.9587019678086386,\n",
       " 0.9561891059442408,\n",
       " 0.9943550796704208,\n",
       " 0.9821992119105171,\n",
       " 0.7836069994121031,\n",
       " 0.07010593938400202,\n",
       " 0.03589735300331573,\n",
       " 0.8761750801115129,\n",
       " 0.9746814709954754,\n",
       " 0.9222234889743599,\n",
       " 0.0006118767951375556,\n",
       " 0.8910644430795442,\n",
       " 0.20186547330030147,\n",
       " 0.7622857917904025,\n",
       " 0.9803302464473357,\n",
       " 0.8779081028467893,\n",
       " 0.1659000240708235,\n",
       " 0.9091582023559993,\n",
       " 0.8983369103291449,\n",
       " 0.5065659928002783,\n",
       " 0.5694302359620455,\n",
       " 0.9378388317620866,\n",
       " 0.9415753536766448,\n",
       " 0.012683694860501811,\n",
       " 0.9899572727377018,\n",
       " 0.01306184434821389,\n",
       " 0.29291018036959776,\n",
       " 0.2394758604360601,\n",
       " 0.022354511323807662,\n",
       " 0.02129461348193594,\n",
       " 0.9783423479531804,\n",
       " 0.9560215702347484,\n",
       " 0.8179998884073486,\n",
       " 0.0027181429619368203,\n",
       " 0.03162347001954333,\n",
       " 0.2216614207617957,\n",
       " 0.014931743706246642,\n",
       " 0.11520124121280438,\n",
       " 0.9820161831963831,\n",
       " 0.04283795134247842,\n",
       " 0.9399041574381759,\n",
       " 0.2755333426672146,\n",
       " 0.5372349319161257,\n",
       " 0.031049683567864222,\n",
       " 0.006802845360967707,\n",
       " 0.3909644421865545,\n",
       " 0.08854293726852504,\n",
       " 0.8805397961487531,\n",
       " 0.3530284641296792,\n",
       " 0.9737269847305126,\n",
       " 0.9951328188414146,\n",
       " 0.8216110979171082,\n",
       " 0.1794163405291715,\n",
       " 0.4826654494067889,\n",
       " 0.022795104244976473,\n",
       " 0.7865191390158174,\n",
       " 0.5445780205747842,\n",
       " 0.05347378691408094,\n",
       " 0.07102968554754588,\n",
       " 0.03155954888194313,\n",
       " 0.009084251171158745,\n",
       " 0.579188111398304,\n",
       " 0.9666808676945216,\n",
       " 0.8718351142156753,\n",
       " 0.9296135669640831,\n",
       " 0.03836841108314084,\n",
       " 0.9960795235932268,\n",
       " 0.9786941794794323,\n",
       " 0.9554608222465196,\n",
       " 0.5656245527866355,\n",
       " 0.04979454656736322,\n",
       " 0.9828417626377166,\n",
       " 0.5610707112616471,\n",
       " 0.9856892223967446,\n",
       " 0.9486284210896069,\n",
       " 0.026009101986250078,\n",
       " 0.010250779014176668,\n",
       " 0.9004415269372146,\n",
       " 0.9990953520880984,\n",
       " 0.8266622537659747,\n",
       " 0.31672404783830305,\n",
       " 0.9936647102484878,\n",
       " 0.3603460526037279,\n",
       " 0.0823147271455816,\n",
       " 0.9169915727916581,\n",
       " 0.01387621778073665,\n",
       " 0.8520371651792781,\n",
       " 0.47688102393652326,\n",
       " 0.9155742920294487,\n",
       " 0.9515435294716998,\n",
       " 0.31066951729562453,\n",
       " 0.0856135876854128,\n",
       " 0.5259097561037083,\n",
       " 0.8832008360959612,\n",
       " 0.3353542976601242,\n",
       " 0.007379077140294572,\n",
       " 0.79946248950762,\n",
       " 0.029804171302909507,\n",
       " 0.08620612498450825,\n",
       " 0.49297185466132587,\n",
       " 0.6368707276106917,\n",
       " 0.07978926848197329,\n",
       " 0.42128205469026087,\n",
       " 0.1767071867020857,\n",
       " 0.9609180023657339,\n",
       " 0.9345889291250911,\n",
       " 0.035326743686170746,\n",
       " 0.08815113688622589,\n",
       " 0.7057255385451655,\n",
       " 0.07358930741447248,\n",
       " 0.41793079728145094,\n",
       " 0.08809947587933212,\n",
       " 0.11209555017959279,\n",
       " 0.002031471878446779,\n",
       " 0.0008107391819579719,\n",
       " 0.928015595785918,\n",
       " 9.503782832125648e-05,\n",
       " 0.7762984579500929,\n",
       " 0.9868757698835622,\n",
       " 0.9712903284425125,\n",
       " 0.00022737711996145065,\n",
       " 0.9370102688279435,\n",
       " 0.012697570706625597,\n",
       " 0.07934573639588233,\n",
       " 0.0017783543159860418,\n",
       " 0.9660814901623328,\n",
       " 0.9965661725870031,\n",
       " 0.9918404174223997,\n",
       " 0.8621115464687917,\n",
       " 0.4062103240436863,\n",
       " 0.3409638803241652,\n",
       " 0.0030001798503097505,\n",
       " 0.17335890096244364,\n",
       " 0.5898117075807575,\n",
       " 0.3818097984476638,\n",
       " 0.29657036388800545,\n",
       " 0.7242418271545027,\n",
       " 0.15446080226214276,\n",
       " 0.9952438832984218,\n",
       " 0.9815291345077006,\n",
       " 0.9416454746403248,\n",
       " 0.9424111749558225,\n",
       " 0.5490550064467182,\n",
       " 0.16151298401102887,\n",
       " 0.7592341114632396,\n",
       " 0.9720193503650427,\n",
       " 3.0584925016226164e-05,\n",
       " 0.9878823814011037,\n",
       " 0.9663488437208105,\n",
       " 0.9363169056697689,\n",
       " 0.8583360073950391,\n",
       " 0.008375101755920777,\n",
       " 0.005086529544059561,\n",
       " 0.1348051917887357,\n",
       " 0.4068210064053473,\n",
       " 0.9804147495843748,\n",
       " 0.8662774798118572,\n",
       " 0.9828545918519251,\n",
       " 0.35813250802336133,\n",
       " 0.3372781664874396,\n",
       " 0.9482631207356785,\n",
       " 0.8415403405949219,\n",
       " 0.34587034043630915,\n",
       " 0.8726420886469914,\n",
       " 0.82052139641706,\n",
       " 0.9998645739743006,\n",
       " 0.008629238624940541,\n",
       " 0.8904838373647272,\n",
       " 0.9912468816118573,\n",
       " 0.08695533273498736,\n",
       " 0.02929723270645884,\n",
       " 0.828624840433194,\n",
       " 0.8782230063800771,\n",
       " 0.006393444834644416,\n",
       " 0.07786695592124683,\n",
       " 0.9332180900979231,\n",
       " 0.9777408100267859,\n",
       " 0.5254567373332767,\n",
       " 0.5666326989186736,\n",
       " 0.9858748598933978,\n",
       " 0.7803705585722567,\n",
       " 0.9382818752665967,\n",
       " 0.06548907204821161,\n",
       " 0.2104648542887439,\n",
       " 0.352463966577314,\n",
       " 0.9221904939306448,\n",
       " 0.24929061294430296,\n",
       " 0.02452384071073476,\n",
       " 0.8778420985107398,\n",
       " 0.8264037051291618,\n",
       " 0.9972758637295386,\n",
       " 0.25858243246521445,\n",
       " 0.945316556596107,\n",
       " 0.47120381796403654,\n",
       " 0.9103719087756884,\n",
       " 0.012531767607075544,\n",
       " 0.9926940094483965,\n",
       " 0.49853815030675236,\n",
       " 0.6001434247069247,\n",
       " 0.660901883545371,\n",
       " 0.0182964322898468,\n",
       " 0.6778442048653898,\n",
       " 0.00012515107599742867,\n",
       " 0.0442011880433531,\n",
       " 0.9186343190771201,\n",
       " 0.45365136712124654,\n",
       " 0.057147167628019545,\n",
       " 0.38471091822694636,\n",
       " 0.9570565230385413,\n",
       " 0.9980536957903169,\n",
       " 0.10960368460354304,\n",
       " 0.4012866198127081,\n",
       " 0.9973356128431384,\n",
       " 0.9910253665318022,\n",
       " 0.42332769053573915,\n",
       " 0.9547644509970783,\n",
       " 0.2181380472415331,\n",
       " 0.4038361038410705,\n",
       " 0.9139408825097151,\n",
       " 0.8437023907449022,\n",
       " 0.8657643240948011,\n",
       " 0.8998351849873246,\n",
       " 0.08488695532093701,\n",
       " 0.9252018933540909,\n",
       " 0.964740764109047,\n",
       " 0.8292795273167298,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure the values were correct\n",
    "y_score_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting y values\n",
    "preds = gs.predict(X_test_tf)\n",
    "\n",
    "# Creating a confusion matrix dataframe \n",
    "pd.DataFrame(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452213220874943"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the roc_auc_score\n",
    "roc_auc_score(y_test, y_score_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is overfit so work needs to be done. \n",
    "# After checking some of the selftexts and title that were misslabeled, the ones that were misslabeled could have been posted to both subreddits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing [removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('[removed]', inplace = True)\n",
    "\n",
    "df.drop(df.loc[df['selftext'] == '[removed]'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.66285\n",
       "0    0.33715\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_selftext'] = df[['title', 'selftext']].apply(lambda x: ''.join(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "storage_sf = []\n",
    "for text in df['title_selftext']:\n",
    "    score = sia.polarity_scores(text)\n",
    "    score['title_selftext'] = text\n",
    "    storage_sf.append(score)\n",
    "df_final = pd.DataFrame(storage_sf)\n",
    "df_final['subreddit'] = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079152</td>\n",
       "      <td>0.819031</td>\n",
       "      <td>0.101819</td>\n",
       "      <td>0.122919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044324</td>\n",
       "      <td>0.842458</td>\n",
       "      <td>0.113214</td>\n",
       "      <td>0.415796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                neg       neu       pos  compound\n",
       "subreddit                                        \n",
       "0          0.079152  0.819031  0.101819  0.122919\n",
       "1          0.044324  0.842458  0.113214  0.415796"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compound seperation is okay\n",
    "# Negative became a much bigger player\n",
    "df_final.groupby('subreddit').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final[['compound', 'neg', 'title_selftext']]\n",
    "y = df_final['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words = 'english')\n",
    "X_train_tf = tf.fit_transform(X_train['title_selftext']).todense()\n",
    "X_test_tf = tf.transform(X_test['title_selftext']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 2.5, 5, 7.5, 10], 'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "params = ({\n",
    "    'C': [1, 2.5, 5, 7.5, 10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "})\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid = params, cv = 5)\n",
    "gs.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689793521871024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885529791605518"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>883</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>2134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  883   266\n",
       "1  124  2134"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting y values\n",
    "preds = gs.predict(X_test_tf)\n",
    "\n",
    "# Creating a confusion matrix dataframe \n",
    "pd.DataFrame(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443552794782076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score_proba = [i[1] for i in gs.predict_proba(X_test_tf)]\n",
    "roc_auc_score(y_test, y_score_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
